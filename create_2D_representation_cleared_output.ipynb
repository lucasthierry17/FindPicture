{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can images be displayed in a 2D way?\n",
    "Images can be displayed in a 2D way by reducing their high-dimensional representations (embeddings) to two dimensions \n",
    "using a dimensionality reduction technique. \n",
    "\n",
    "- Embedding Extraction: Extract feature vectors (embeddings) from images using models like convolutional neural networks (CNNs).\n",
    "- Dimensionality Reduction: Apply a dimensionality reduction algorithm, such as t-SNE (t-distributed Stochastic Neighbor Embedding), \n",
    "to map high-dimensional embeddings to a 2D space.\n",
    "\n",
    "## How does the code work?\n",
    "The code is based on the embedding_resnet.ipynb, in which the pickle files of the image_paths and the embeddigns are being created. \n",
    "This code goes through several steps: \n",
    "1. Load the files needed (image_paths and embeddigns)\n",
    "2. Extract the parent folder name of each image (function: extract_category_from_path)\n",
    "3. Store the category name in a list\n",
    "4. Perform the TSNE dimensionality reduction on the embeddings (see further down for the explanation)\n",
    "5. Store the data for the visualisation in a dataframe\n",
    "6. Plot the results (with the plotly library, so one can hover over it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the TSNE dimensionality reduction work?\n",
    "1. Pairwise Similarities: Calculating the pairwise similarities between all points in the high-dimensional space.\n",
    "2. Probability Distributions: Converting these similarities into probability distributions. Similar points have higher probabilities of being neighbors.\n",
    "3. Minimizing Kullback-Leibler Divergence: Mapping these probabilities to a lower-dimensional space (usually 2D) by minimizing \\\n",
    "the Kullback-Leibler divergence between the probability distributions of the high-dimensional space and the \\\n",
    "lower-dimensional space. This ensures that similar points in high dimensions are close in the lower dimensions.\n",
    "\n",
    "For further explanations you can watch this video: https://www.youtube.com/watch?v=NEaUSP4YerM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings and image paths\n",
    "embeddings_path = 'embeddings_all.pkl'\n",
    "image_paths_path = 'image_paths_all.pkl'\n",
    "\n",
    "if not os.path.exists(embeddings_path) or not os.path.exists(image_paths_path):\n",
    "    print(\"No file found with the specified name, maybe create the pickle files first?\")\n",
    "else:\n",
    "    with open(embeddings_path, 'rb') as f:\n",
    "        embeddings = pickle.load(f)\n",
    "    with open(image_paths_path, 'rb') as f:\n",
    "        image_paths = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_category_from_path(path, depth):\n",
    "    # Split the path into its components\n",
    "    path_parts = path.split(sep)\n",
    "    # Ensure the depth is within the valid range\n",
    "    if 0 <= depth < len(path_parts):\n",
    "        return path_parts[depth]\n",
    "    else:\n",
    "        raise ValueError(f\"Specified depth {depth} is out of range for the given path\")\n",
    "\n",
    "# please test the depth of the path you want to have\n",
    "sep = \"\\\\\" # how are the paths seperated \n",
    "depth = 3 # replace by the depth of the path you want (count slashes to find depth)\n",
    "# Extract the first 5 paths\n",
    "first_path = image_paths[0]\n",
    "print(first_path)\n",
    "extract_category_from_path(first_path, depth)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [extract_category_from_path(path, depth) for path in image_paths]\n",
    "print(f\"This is the length of the categories list: {len(categories)}\") # should be the number of images you want to plot\n",
    "\n",
    "# Perform t-SNE dimensionality reduction\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "embeddings_2d = tsne.fit_transform(embeddings)\n",
    "print(f\"This is the shape of the embeddings in 2D: {embeddings_2d.shape}\")\n",
    "\n",
    "# Prepare data for plotting\n",
    "plot_data = {\n",
    "    'x': embeddings_2d[:, 0],\n",
    "    'y': embeddings_2d[:, 1],\n",
    "    'path': image_paths,\n",
    "    'category': categories\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the visualisation\n",
    "df = pd.DataFrame(plot_data)\n",
    "print(df.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do similar images have close images?\n",
    "- Preservation of Local structure: TSNE aims to preserve the local structure of the high-dimensional data in the 2D map. This means that imageas that are close \\\n",
    "in the high-dimensional space are also close in the 2D representation\n",
    "- High Probability of being neighbors: TSNE assigns higher probabilites to pairs of points that are similar and places them closer together in the 2D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the interactive plot\n",
    "fig = px.scatter(\n",
    "    df, \n",
    "    x='x', \n",
    "    y='y', \n",
    "    color='category',\n",
    "    hover_data={'path': True, 'x': False, 'y': False}\n",
    ")\n",
    "\n",
    "# Add hover template to show path, x, and y coordinates\n",
    "fig.update_traces(\n",
    "    hovertemplate=\"<br>\".join([\n",
    "        \"Path: %{customdata[0]}\",\n",
    "        \"x: %{x}\",\n",
    "        \"y: %{y}\"\n",
    "    ]),\n",
    "    opacity = 0.2 # alpha value \n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='t-SNE Visualization of Image Embeddings',\n",
    "    xaxis_title='Dimension 1',\n",
    "    yaxis_title='Dimension 2',\n",
    "    width=1200,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
